{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T05:03:04.659545Z",
     "start_time": "2018-05-15T05:03:03.055089Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "#from azureml.dataprep import package\n",
    "\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "def removeString(data, regex):\n",
    "    return data.str.lower().str.replace(regex.lower(), ' ')\n",
    "\n",
    "\n",
    "\n",
    "def cleanDataset(dataset, columnsToClean, regexList):\n",
    "    for column in columnsToClean:\n",
    "        for regex in regexList:\n",
    "            dataset[column] = removeString(dataset[column], regex)\n",
    "    return dataset\n",
    "\n",
    "stopwords_fileids_custom=['english','french']\n",
    "\n",
    "def _calc_ratios(text):\n",
    "    ratios = {}\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    words = [word.lower() for word in tokens]\n",
    "#    for lang in stopwords.fileids():\n",
    "    for lang in stopwords_fileids_custom:\n",
    "        stopwords_set = set(stopwords.words(lang))\n",
    "        words_set = set(words)\n",
    "        common_words = words_set.intersection(stopwords_set)\n",
    "        ratios[lang] = len(common_words)\n",
    "    \n",
    "    is_english=ratios['english']>ratios['french']\n",
    "\n",
    "    return is_english\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Init_RegexList():\n",
    "    regexList = []\n",
    "    regexList += ['https?:[^\\]\\n\\r]+']  # https & http\n",
    "    regexList += ['[\\w\\d\\-\\_\\.]+@[\\w\\d\\-\\_\\.]+']  # emails\n",
    "    regexList += ['[0-9][\\-0–90-9 ]+']  # phones\n",
    "    regexList += ['[0-9]']  # numbers\n",
    "    # regexList += ['[^a-zA-z 0-9]+']  # anything that is not a letter\n",
    "    # regexList += ['[\\r\\n]']  # \\r\\n\n",
    "    # regexList += [' [a-zA-Z] ']  # single letters\n",
    "    # regexList += [' [a-zA-Z][a-zA-Z] ']  # two-letter words\n",
    "    #regexList += [\"  \"]  # double spaces\n",
    "\n",
    "    #regexList += ['^[_a-z0-9-]+(\\.[_a-z0-9-]+)*@[a-z0-9-]+(\\.[a-z0-9-]+)*(\\.[a-z]{2,4})$']\n",
    "    #regexList += ['[\\w\\d\\-\\_\\.]+ @ [\\w\\d\\-\\_\\.]+']\n",
    "    #regexList += ['[^a-zA-Z]']\n",
    "    return regexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegexList():\n",
    "    regexList = []\n",
    "    regexList += ['From:']  # from line\n",
    "    # regexList += ['RITM[0-9]*'] # request id\n",
    "    # regexList += ['INC[0-9]*'] # incident id\n",
    "    # regexList += ['TKT[0-9]*'] # ticket id\n",
    "    regexList += ['Sent:']  # sent to line\n",
    "    regexList += ['Received:']  # received data line\n",
    "    regexList += ['To:','À:']  # to line\n",
    "    regexList += ['CC:','Cc:']  # cc line\n",
    "    #regexList += ['The information(.*)infection']  # footer\n",
    "    #regexList += ['Endava Limited is a company(.*)or omissions']  # footer\n",
    "    #regexList += ['The information in this email is confidential and may be legally(.*)interference if you are not the intended recipient']  # footer\n",
    "    regexList += ['\\[cid:(.*)]']  # images cid\n",
    "    regexList += ['https?:[^\\]\\n\\r]+']  # https & http\n",
    "    regexList += ['Subject:','Objet:','Object:']\n",
    "    # regexList += ['[\\w\\d\\-\\_\\.]+@[\\w\\d\\-\\_\\.]+']  # emails\n",
    "    # regexList += ['[0-9][\\-0–90-9 ]+']  # phones\n",
    "    # regexList += ['[0-9]']  # numbers\n",
    "    # regexList += ['[^a-zA-z 0-9]+']  # anything that is not a letter\n",
    "    # regexList += ['[\\r\\n]']  # \\r\\n\n",
    "    regexList += [' [a-zA-Z] ']  # single letters\n",
    "    # regexList += [' [a-zA-Z][a-zA-Z] ']  # two-letter words\n",
    "    regexList += [\"  \"]  # double spaces\n",
    "\n",
    "    regexList += ['^[_a-z0-9-]+(\\.[_a-z0-9-]+)*@[a-z0-9-]+(\\.[a-z0-9-]+)*(\\.[a-z]{2,4})$']\n",
    "    regexList += ['[\\w\\d\\-\\_\\.]+ @ [\\w\\d\\-\\_\\.]+']\n",
    "    #regexList += ['[^a-zA-Z]']\n",
    "    # Customized Part\n",
    "    cust_stopwords=[]\n",
    "    cust_stopwords+=['Note: Please check the attachments tab for complete email including print screens or attachments']\n",
    "    cust_stopwords+=['Importance','urgent','Tel','Fax']\n",
    "    cust_stopwords+=['Descriptif de','incident :','Depuis quand :','Information requises :']\n",
    "    cust_stopwords+=['Localisation :','Actions réalisées:']\n",
    "    cust_stopwords+=['imPulse','Ticket','Description','Note']\n",
    "    \n",
    "    regexList=regexList+cust_stopwords\n",
    "    return regexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### function-like substitute for Type Alias Python Problem!!!\n",
    "def cleanText(text, regexList):\n",
    "    text=text.lower()\n",
    "    for regex in regexList:\n",
    "        text=re.sub(regex,'', text)\n",
    "    return text\n",
    "\n",
    "def cleanDataset2(dataset, columnsToClean, regexList):\n",
    "    for column in columnsToClean:\n",
    "        dataset[column] = dataset[column].apply(lambda x: cleanText(x, regexList)) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T05:03:30.130318Z",
     "start_time": "2018-05-15T05:03:04.665545Z"
    }
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Load non duplicated ############### Dictionary of text Formats ###################\n",
    "\n",
    "# Email_like format\n",
    "regex_Email_like = r\"(su|o)?b?jec?t(.*?):(.*?(:|$))\"\n",
    "# Impulse_like format\n",
    "regex_Impulse_like =r\"ticket description =========================================(.*?):(.*?(:|$))\"\n",
    "# Incident_Like format\n",
    "regex_Incident_like =r\"descriptif de l'incident(.*?):(.*?(:|$))\"\n",
    "# Description_Like format\n",
    "#regex_Description_like =r\"descript(.*?):(.*?(:|$))\"\n",
    "regex_Description_like =r\"sdqsdqsdqsdqdescript(.*?):(.*?(:|$))\"\n",
    "\n",
    "\n",
    "# Save to format dictionary\n",
    "Dict_Format={'Email_like':regex_Email_like,'Impulse_like':regex_Impulse_like,'Incident_like':regex_Incident_like,'Description_like':regex_Description_like}\n",
    "# Array of different text format regex\n",
    "Array_Format=list(Dict_Format.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate format for each text field\n",
    "def format_type(text):\n",
    "    text_format='free' # return free format by default\n",
    "    for (k,v) in Dict_Format.items():\n",
    "        if bool(re.search(v, text)):\n",
    "            text_format=k\n",
    "            break\n",
    "    return text_format\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'***********impulse ticket description =========================================end user: bernoussi seif (seif.bernoussi)category: eus_applicationssubcategory: standard_applicationsopened by: mustacchi moiseopen date: 2017-10-24 14:21:01creator group: gts'"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=regex_Impulse_like\n",
    "re.search(v, text)==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"***********impulse ticket description =========================================end user: bernoussi seif (seif.bernoussi)category: eus_applicationssubcategory: standard_applicationsopened by: mustacchi moiseopen date: 2017-10-24 14:21:01creator group: gts\"\n",
    "text\n",
    "bool(re.search(r\"ticket description =========================================(.*?):(.*?(:|$))\",text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load dataset from non duplicated file\n",
    "filepath=\"PGS-IN.csv\"\n",
    "dfTickets=pd.read_csv(filepath,sep=\";\",encoding=\"iso-8859-1\")\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only meaningful fields: Title, Incident Description, Solution Journal Events and Id_Incident(Not meaningful)\n",
    "# Reorder columns\n",
    "columnsFilter = ['ID Incident','IN - Incident Description']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T05:03:30.196341Z",
     "start_time": "2018-05-15T05:03:30.134320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfIncidents shape: (20009, 22)\n"
     ]
    }
   ],
   "source": [
    "print('dfIncidents shape:',dfTickets.shape)\n",
    "dfTickets[columnsFilter].head(n=5)\n",
    "s=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove text with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## First Step of Cleaning ##############\n",
    "columnsToClean=['IN - Incident Description']\n",
    "dfTickets_clean_1=dfTickets.copy()\n",
    "cleanDataset2(dfTickets_clean_1, columnsToClean,  get_Init_RegexList())\n",
    "#get_Init_RegexList()\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding new field for text format\n",
    "dfTickets_format=dfTickets.copy()\n",
    "dfTickets_format['Incident-format']=dfTickets_format['IN - Incident Description'].str.lower().apply(format_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"***********---------------------------------------------------------------------------------descriptif de l'incident : monsieur souhaite avoir une secure id.depuis quand :message d'erreur :---------------------------------------------------------------------------------information requises : ca 17985nom du matérie l: ma7140659los : w7téléphone (complet) : +33 1 56 37 96 03localisation : pme167---------------------------------------------------------------------------------actions réalisées: escalade au groupe achat.---------------------------------------------------------------------------------**********************\""
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=i+1\n",
    "text=dfTickets['IN - Incident Description'][i].lower()\n",
    "text\n",
    "#text.split('\\n')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Impulse_like'"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets_format['Incident-format'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris ACL operation'"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets['IN - Title'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### properties ###export name  \\\\\\\\nas\\\\pfcnoyh$  and \\\\\\\\nas\\\\pfcdfph$ read/write access to remove '"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets_clean_3['IN - Incident Description'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*********** *** note: please check the attachments tab for complete email including print screens or attachments ***     de : falaise wilfrid (ext) itecmktvol  envoyé : friday, november , :pm à : call-center cc : mekdad tarik itecmktvol objet : licences ag-grid     bonjour,   j\\x92ai récemment effectué une demande de licence pour le composant ag-grid. (demande serval: user_(validated) - ticket associé: ritm) pourriez vous me contacter à ce sujet ? je souhaiterais commencer à intégrer ce composant dans nos solutions.   cordialement,   wf**********************'"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets_clean_1['IN - Incident Description'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"descriptif de l'incident : poste très lent , perte réseau , plus de connexion outlookdepuis quand :\""
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets_clean_2['IN - Incident Description'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Custom_RegexList():\n",
    "    regexList = []\n",
    "    regexList += ['(su|o)?b?jec?t(.*?):']  # subject,objet\n",
    "    regexList += ['description =========================================(.*?)']  # impulse ticket description\n",
    "    regexList += ['impulse','ticket']  # impulse ticket description\n",
    "    regexList += [\"descriptif de l'incident(.*?):\"]  # descriptif de l'incident\n",
    "    regexList += ['depuis quand ']  # Depuis quand \n",
    "    regexList += ['further *information *from','=',':','\\*','-'] # further information from ===========================\n",
    "    regexList += ['end *user.*']# kick out end user .......\n",
    "    regexList += ['information *requises.*'] # kick out information requises .......\n",
    "    regexList += ['pouvez *vous voir','il vous plait']# Pouvez-vous voir s\\'il vous plait\n",
    "    #regexList += ['^\\w'] # symbols\n",
    "    return regexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a specific text portion according to regex pattern\n",
    "def extract_regex(text,Dict):\n",
    "    if format_type(text)!='free':\n",
    "        return re.search(Dict[format_type(text)], text).group(0)\n",
    "    else:\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_regex(text,Dict_Format)\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_clean_2=dfTickets_clean_1.copy()\n",
    "dfTickets_clean_2['IN - Incident Description']=dfTickets_clean_2['IN - Incident Description'].apply(lambda x: extract_regex(x,Dict_Format) )\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_clean_3=dfTickets_clean_2.copy()\n",
    "cleanDataset2(dfTickets_clean_3, columnsToClean,  get_Custom_RegexList())\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID Incident                       object\n",
       "IN - Incident Type                object\n",
       "IN - Critical User                object\n",
       "IN - 001 - Contact Entity         object\n",
       "IN - Status                       object\n",
       "IN - Service                      object\n",
       "IN - Category                     object\n",
       "IN - Sub-Category                 object\n",
       "IN - Characterisation             object\n",
       "IN - Title                        object\n",
       "IN - Incident Description         object\n",
       "IN - Solution                     object\n",
       "IN - Open Time                    object\n",
       "IN - Close Date                   object\n",
       "IN - Assignment Group             object\n",
       "IN - EUS - Follow Group           object\n",
       "IN - Open By Group                object\n",
       "IN - Restored By Group            object\n",
       "IN - Previous Assignment Group    object\n",
       "IN - Activity Description         object\n",
       "IN - Activity Date                object\n",
       "IN - Clock Group                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silver'"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTickets['IN - Critical User'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
