{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T05:03:04.659545Z",
     "start_time": "2018-05-15T05:03:03.055089Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import preprocessing\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "#from azureml.dataprep import package\n",
    "\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "def removeString(data, regex):\n",
    "    return data.str.lower().str.replace(regex.lower(), ' ')\n",
    "\n",
    "\n",
    "\n",
    "def cleanDataset(dataset, columnsToClean, regexList):\n",
    "    for column in columnsToClean:\n",
    "        for regex in regexList:\n",
    "            dataset[column] = removeString(dataset[column], regex)\n",
    "    return dataset\n",
    "\n",
    "stopwords_fileids_custom=['english','french']\n",
    "\n",
    "def _calc_ratios(text):\n",
    "    ratios = {}\n",
    "    tokens = wordpunct_tokenize(text)\n",
    "    words = [word.lower() for word in tokens]\n",
    "#    for lang in stopwords.fileids():\n",
    "    for lang in stopwords_fileids_custom:\n",
    "        stopwords_set = set(stopwords.words(lang))\n",
    "        words_set = set(words)\n",
    "        common_words = words_set.intersection(stopwords_set)\n",
    "        ratios[lang] = len(common_words)\n",
    "    \n",
    "    is_english=ratios['english']>ratios['french']\n",
    "\n",
    "    return is_english\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Init_RegexList():\n",
    "    regexList = []\n",
    "    regexList += ['https?:[^\\]\\n\\r]+']  # https & http\n",
    "    regexList += ['[\\w\\d\\-\\_\\.]+@[\\w\\d\\-\\_\\.]+']  # emails\n",
    "    regexList += ['[0-9][\\-0–90-9 ]+']  # phones\n",
    "    regexList += ['[0-9]']  # numbers\n",
    "    # regexList += ['[^a-zA-z 0-9]+']  # anything that is not a letter\n",
    "    # regexList += ['[\\r\\n]']  # \\r\\n\n",
    "    # regexList += [' [a-zA-Z] ']  # single letters\n",
    "    # regexList += [' [a-zA-Z][a-zA-Z] ']  # two-letter words\n",
    "    #regexList += [\"  \"]  # double spaces\n",
    "\n",
    "    #regexList += ['^[_a-z0-9-]+(\\.[_a-z0-9-]+)*@[a-z0-9-]+(\\.[a-z0-9-]+)*(\\.[a-z]{2,4})$']\n",
    "    #regexList += ['[\\w\\d\\-\\_\\.]+ @ [\\w\\d\\-\\_\\.]+']\n",
    "    #regexList += ['[^a-zA-Z]']\n",
    "    return regexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRegexList():\n",
    "    regexList = []\n",
    "    regexList += ['From:']  # from line\n",
    "    # regexList += ['RITM[0-9]*'] # request id\n",
    "    # regexList += ['INC[0-9]*'] # incident id\n",
    "    # regexList += ['TKT[0-9]*'] # ticket id\n",
    "    regexList += ['Sent:']  # sent to line\n",
    "    regexList += ['Received:']  # received data line\n",
    "    regexList += ['To:','À:']  # to line\n",
    "    regexList += ['CC:','Cc:']  # cc line\n",
    "    #regexList += ['The information(.*)infection']  # footer\n",
    "    #regexList += ['Endava Limited is a company(.*)or omissions']  # footer\n",
    "    #regexList += ['The information in this email is confidential and may be legally(.*)interference if you are not the intended recipient']  # footer\n",
    "    regexList += ['\\[cid:(.*)]']  # images cid\n",
    "    regexList += ['https?:[^\\]\\n\\r]+']  # https & http\n",
    "    regexList += ['Subject:','Objet:','Object:']\n",
    "    # regexList += ['[\\w\\d\\-\\_\\.]+@[\\w\\d\\-\\_\\.]+']  # emails\n",
    "    # regexList += ['[0-9][\\-0–90-9 ]+']  # phones\n",
    "    # regexList += ['[0-9]']  # numbers\n",
    "    # regexList += ['[^a-zA-z 0-9]+']  # anything that is not a letter\n",
    "    # regexList += ['[\\r\\n]']  # \\r\\n\n",
    "    regexList += [' [a-zA-Z] ']  # single letters\n",
    "    # regexList += [' [a-zA-Z][a-zA-Z] ']  # two-letter words\n",
    "    regexList += [\"  \"]  # double spaces\n",
    "\n",
    "    regexList += ['^[_a-z0-9-]+(\\.[_a-z0-9-]+)*@[a-z0-9-]+(\\.[a-z0-9-]+)*(\\.[a-z]{2,4})$']\n",
    "    regexList += ['[\\w\\d\\-\\_\\.]+ @ [\\w\\d\\-\\_\\.]+']\n",
    "    #regexList += ['[^a-zA-Z]']\n",
    "    # Customized Part\n",
    "    cust_stopwords=[]\n",
    "    cust_stopwords+=['Note: Please check the attachments tab for complete email including print screens or attachments']\n",
    "    cust_stopwords+=['Importance','urgent','Tel','Fax']\n",
    "    cust_stopwords+=['Descriptif de','incident :','Depuis quand :','Information requises :']\n",
    "    cust_stopwords+=['Localisation :','Actions réalisées:']\n",
    "    cust_stopwords+=['imPulse','Ticket','Description','Note']\n",
    "    \n",
    "    regexList=regexList+cust_stopwords\n",
    "    return regexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### function-like substitute for Type Alias Python Problem!!!\n",
    "def cleanText(text, regexList):\n",
    "    text=text.lower()\n",
    "    for regex in regexList:\n",
    "        text=re.sub(regex,'', text)\n",
    "    return text\n",
    "\n",
    "def cleanDataset2(dataset, columnsToClean, regexList):\n",
    "    for column in columnsToClean:\n",
    "        dataset[column] = dataset[column].apply(lambda x: cleanText(x, regexList)) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T05:03:30.130318Z",
     "start_time": "2018-05-15T05:03:04.665545Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Load non duplicated ############### Dictionary of text Formats ###################\n",
    "\n",
    "# Email_like format\n",
    "regex_Email_like = r\"(su|o)?b?jec?t(.*?):(.*?(:|$))\"\n",
    "# Impulse_like format\n",
    "regex_Impulse_like =r\"description =========================================(.*?):(.*?(:|$))\"\n",
    "# Incident_Like format\n",
    "regex_Incident_like =r\"descriptif de l'incident(.*?):(.*?(:|$))\"\n",
    "# Description_Like format\n",
    "regex_Description_like =r\"descript(.*?):(.*?(:|$))\"\n",
    "\n",
    "\n",
    "# Save to format dictionary\n",
    "Dict_Format={'Email_like':regex_Email_like,'Impulse_like':regex_Impulse_like,'Incident_like':regex_Incident_like,'Description_like':regex_Description_like}\n",
    "# Array of different text format regex\n",
    "Array_Format=list(Dict_Format.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate format for each text field\n",
    "def format_type(text):\n",
    "    for (k,v) in Dict_Format.items():\n",
    "        if re.search(v, text): \n",
    "            return k\n",
    "    else:\n",
    "        return 'free' # return free format by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Load dataset from non duplicated file\n",
    "filepath=r\"PGS-IN_non_duplicated.csv\"\n",
    "dfTickets=pd.read_csv(filepath,sep=\";\",encoding=\"iso-8859-1\")\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep only meaningful fields: Title, Incident Description, Solution Journal Events and Id_Incident(Not meaningful)\n",
    "# Reorder columns\n",
    "columnsFilter = ['ID Incident',' Incident Description']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-15T05:03:30.196341Z",
     "start_time": "2018-05-15T05:03:30.134320Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfIncidents shape: (20663, 22)\n"
     ]
    }
   ],
   "source": [
    "print('dfIncidents shape:',dfTickets.shape)\n",
    "dfTickets[columnsFilter].head(n=5)\n",
    "s=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove text with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############## First Step of Cleaning ##############\n",
    "columnsToClean=[' Incident Description']\n",
    "dfTickets_clean_1=dfTickets.copy()\n",
    "cleanDataset2(dfTickets_clean_1, columnsToClean,  get_Init_RegexList())\n",
    "#get_Init_RegexList()\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=i+1\n",
    "text=dfTickets[' Incident Description'][i]\n",
    "s=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTickets_clean_1[' Incident Description'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTickets_clean_2[' Incident Description'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTickets_clean_3[' Incident Description'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Custom_RegexList():\n",
    "    regexList = []\n",
    "    regexList += ['(su|o)?b?jec?t(.*?):']  # subject,objet\n",
    "    regexList += ['description =========================================(.*?)']  # impulse ticket description\n",
    "    regexList += ['impulse','ticket']  # impulse ticket description\n",
    "    regexList += [\"descriptif de l'incident(.*?):\"]  # descriptif de l'incident\n",
    "    regexList += ['depuis quand ']  # Depuis quand \n",
    "    regexList += ['further *information *from','=',':','\\*','-'] # further information from ===========================\n",
    "    regexList += ['end *user.*']# kick out end user .......\n",
    "    regexList += ['information *requises.*'] # kick out information requises .......\n",
    "    regexList += ['pouvez *vous voir','il vous plait']# Pouvez-vous voir s\\'il vous plait\n",
    "    #regexList += ['^\\w'] # symbols\n",
    "    return regexList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "format_type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract a specific text portion according to regex pattern\n",
    "def extract_regex(text,Dict):\n",
    "    if format_type(text)!='free':\n",
    "        return re.search(Dict[format_type(text)], text).group(0)\n",
    "    else:\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_regex(text,Dict_Format)\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTickets_clean_2=dfTickets_clean_1.copy()\n",
    "dfTickets_clean_2[' Incident Description']=dfTickets_clean_2[' Incident Description'].apply(lambda x: extract_regex(x,Dict_Format) )\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTickets_clean_3=dfTickets_clean_2.copy()\n",
    "cleanDataset2(dfTickets_clean_3, columnsToClean,  get_Custom_RegexList())\n",
    "s=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
